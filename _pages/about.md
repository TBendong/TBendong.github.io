---
layout: about
title: About
permalink: /
subtitle: Incoming Assistant Professor@PolyU

profile:
  align: left
  image: photo.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
      <a href="https://www.linkedin.com/in/bendong-tan-453046182/"><i class="fa-brands fa-linkedin fa-2x"></i></a>
      <a href="https://scholar.google.com/citations?user=FdEP8xgAAAAJ&hl=en"><i class="ai ai-google-scholar-square ai-2x"></i></a>
      <a href="https://www.zhihu.com/people/tan-ben-dong"><i class="fa-brands fa-zhihu fa-2x"></i></a>
      <a href="https://www.researchgate.net/profile/Bendong-Tan?ev=hdr_xprf"><i class="fa-brands fa-researchgate fa-2x"></i></a>
      <a href="https://orcid.org/my-orcid?orcid=0000-0003-1701-1577"><i class="fa-brands fa-orcid fa-2x"></i></a>
      <a href="https://github.com/TBendong"><i class="fa-brands fa-square-github fa-2x"></i></a>
      
news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
awards: true
social: false # includes social icons at the bottom of the page
---

As a Senior Research Scientist at **Kunlun Tech**, I lead a team developing cutting-edge large multimodal models, with expertise in Diffusion and VLM technologies. My tenure at **Meituan's Autonomous Delivery Department** as a Research Scientist equipped me with a robust understanding of real-world applications of AI.

I obtained my Ph.D. degree from School of Artificial Intelligence and Automation, **Huazhong University of Science and Technology** in 2021, under the expert guidance of [Prof. Nong Sang](https://scholar.google.com/citations?user=ky_ZowEAAAAJ&hl=zh-CN) and [Prof. Changxin Gao](https://scholar.google.com/citations?user=4tku-lwAAAAJ&hl=zh-CN). My academic journey was further enriched by a visiting Ph.D. position at the Australian Institute for Machine Learning, **University of Adelaide**, where I worked closely with [Prof. Chunhua Shen](https://scholar.google.com/citations?user=Ljk2BvIAAAAJ&hl=zh-CN). During my doctoral studies, I received the **Excellent Doctoral Dissertation Award** (one of only 10 students in the country).

My industry experience includes being a research intern at **Microsoft Research Asia** and **Megvii (Face++)**, where I collaborated with [Dr. Jingdong Wang](https://jingdongwang2017.github.io/), [Dr. Gang Yu](https://www.skicyyu.org/), and [Dr. Jian Sun](https://scholar.google.com/citations?user=ALVSZAYAAAAJ&hl=en). I was part of the winning team at the COCO & Mapillary Panoptic Segmentation Challenge 2018.

Recent Updates
----
<div style="display: grid; grid-template-columns: auto auto; gap: 12px;">
<span style="color: #4F81BD;">Jan 2025</span>  <span> Our paper on distributed control and reinforcement learning for network system <a href="https://arxiv.org/abs/2410.17221">Scalable Spectral Representations for Multi-agent Reinforcement Learning in Network MDPs
</a> is accepted to AISTATS 2025! Feel free to check it out!
</span>
<span style="color: #4F81BD;">Sep 2024</span>  <span> Our paper (one of my favorite works!) <a href="https://arxiv.org/abs/2209.14376">On the Optimal Control of Network LQR with Spatially-exponential Decaying Structure</a> is accepted to Automatica! Feel free to check it out!
</span>
<span style="color: #4F81BD;">Aug 2024</span>  <span>I'm very honored to be selected as <a href="https://risingstars-eecs.mit.edu/"> rising star in EECS 2024</a>!
</span>
<span style="color: #4F81BD;">June 2024</span>  <span>Check out our new paper: <a href="https://arxiv.org/abs/2406.08844">Equilibrium Selection for Multi-agent Reinforcement Learning</a>!
</span>
<span style="color: #4F81BD;">Apr 2024</span>  <span>Our paper <a href="https://arxiv.org/abs/2404.05995">Multi-Agent Coverage Control with Transient Behavior Consideration
</a> is accepted to L4DC. The paper provides a provably efficient algorithm for coverage control of multi-robot systems in unknown environments. Feel free to check it out! 
</span>
<span style="color: #4F81BD;">Feb 2024</span>  <span>Our paper <a href="https://arxiv.org/abs/2106.00198">Gradient play in stochastic games: stationary points, convergence, and
sample complexity</a> is accepted to Transaction of Automatic Control (TAC)! 
</span>
<span style="color: #4F81BD;">Jan 2024</span>  <span>Our paper <a href="https://arxiv.org/abs/2306.11626">Soft Robust MDPs and Risk-Sensitive MDPs: Equivalence, Policy Gradient, and Sample Complexity</a> is accepted to ICLR.  
</span>
<span style="color: #4F81BD;">Jan 2024</span>  <span>Two papers are accepted to the American Control Conference (ACC)! Check them out <a href="https://arxiv.org/abs/2401.16183">here</a> and <a href="https://arxiv.org/abs/2401.10383">here</a>.
</span>
<span style="color: #4F81BD;">July 2023</span>  <span> Our paper  <a href="https://arxiv.org/abs/2304.03840">Markov Games with Decoupled Dynamics: Price of Anarchy and Sample Complexity
</a> is accepted to the Conference on Decision and Control (CDC)!
</span>
<span style="color: #4F81BD;">Sep 2022</span>  <span> Two papers on multi-agent RL is accepted to NeurIPS! See you in New Orleans! Check them out <a href="https://arxiv.org/abs/2202.00872">here</a> (Markov potential games) and <a href="https://arxiv.org/abs/2206.02640">here</a> (two-player zero-sum games).
</span>
</div>
